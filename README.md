# Прогнозирование заездов и отмен бронирования в отеле с помощью методов машинного обучения

Массовые отмены онлайн-бронирований снижают доходы отелей. ML-модель предскажет риск отмены, помогая минимизировать потери.

**Задача:** Разработать модель машинного обучения, которая на основе исторических данных о бронированиях отеля предсказывает, отменит ли клиент бронирование (заезд не состоится) или же выполнит его (заезд состоится).

## Обработка данных
В начале работы с данными производится загрузка и предобработка данных. Сначала импортируются нужные библиотеки. Далее загружается набор данных. Затем производится поиск аномалий в данных и удаление этих аномалий.

Следующий шаг включает очистку данных. Пропущенные значения выявить с помощью isnull().sum(). Пропуски отсутствуют.

Далее производится обзор данных с использованием основных статистик. Проверка на дубликаты показала их отсутствие.

На шаге анализа числовых переменных были построены гистограммы распределенй числовых признаков. Затем был произведен анализ выбросов, анализ времени бронирования и построены распределения ключевых числовых параметров.

На шаге анализа категориальных переменных было построено распределение типов питания, распределение типов питания в зависимости от статуса бронирования. Проведена проверка аномалий в основных категориальных переменных. Визуализирована доля типов номеров и статус брони по типам номеров. Построено распределение каналов бронирования, тв том числе в зависимости от статуса бронирования. Построено распределение статусов (доля отмен и подтверждений).

## Создание и анализ новых признаков
Длительность проживания:
````
df['lenght_of_stay'] = df['no_of_week_nights'] + df['no_of_weekend_nights']
````
Количество гостей:
````
df['total_guests'] = df['no_of_adults'] + df['no_of_children']
````
Тип размещения:
````
df['type_of_accommodation'] = pd.cut(
    df['lenght_of_stay'],
    bins=[0, 2, 5, 100],
    labels=['short', 'middle', 'long']
)
````
Тип группы:
````
df['group_type'] = pd.cut(
    df['total_guests'],
    bins=[0, 1, 2, 4, 100],
    labels=['one', 'pair', 'family', 'group']
)
````
Тип бронирования:
````
df['booking_type'] = pd.cut(
    df['lead_time'],
    bins=[-1, 3, 30, 365],
    labels=['last moment', 'standard', 'early']
)
````
Сезон:
````
df['season'] = pd.cut(
    df['arrival_month'],
    bins=[0, 2, 5, 8, 11, 12],
    labels=['winter', 'spring', 'summer', 'autumn', 'winter'],
    ordered=False
)
````
На следующем шаге проводится проверка созданных признаков. Были построены распределения значений по типу размещения, типу группы, типу бронирования, сезону, длительности прожтвания, количеству гостей. Проанализированы выбросы по длительности проживания, количеству гостей, типу бронирования. Также была построена матрица корреляции числовых признаков.

## Отбор признаков
Выполнено разделение на признаки и целевую переменную. Проведено кодирование целевой переменной. 
### Метод на основе дисперсии
После удаления признаков с дисперсией < 0.01 осталось 23 из 27 признаков: Index(['no_of_adults', 'no_of_children', 'no_of_weekend_nights',
       'no_of_week_nights', 'type_of_meal_plan', 'required_car_parking_space',
       'lead_time', 'arrival_month', 'arrival_date', 'market_segment_type',
       'repeated_guest', 'no_of_previous_cancellations',
       'no_of_previous_bookings_not_canceled', 'avg_price_per_room',
       'no_of_special_requests', 'lenght_of_stay', 'total_guests',
       'type_of_accommodation', 'group_type', 'booking_type', 'season',
       'room_type_reserved_Room_Type 2', 'room_type_reserved_Room_Type 4'],
      dtype='object')
### Корреляционный анализ
Построена матрица корреляции числовых признаков и удалены сильно коррелирующие (> 0.8) признаки: ['lenght_of_stay', 'total_guests']
### Principal component analysis (метод главных компонент)
Было выбрано 22 компоненты, объясняющих 95% дисперсии.
### Recursive Feature Elimination (метод рекурсивного исключения признаков)
Лучшие признаки по RFE: ['no_of_adults', 'no_of_weekend_nights', 'no_of_week_nights', 'type_of_meal_plan', 'lead_time', 'arrival_month', 'arrival_date', 'market_segment_type', 'avg_price_per_room', 'no_of_special_requests', 'lenght_of_stay', 'total_guests', 'type_of_accommodation', 'booking_type', 'season']
### Feature importance (методы оценки значимости признаков)
С помощью Random Forest определена важность признаков. Топ-15 важных признаков: ['lead_time', 'avg_price_per_room', 'no_of_special_requests', 'arrival_date', 'arrival_month', 'market_segment_type', 'booking_type', 'lenght_of_stay', 'no_of_week_nights', 'season', 'no_of_weekend_nights', 'type_of_meal_plan', 'type_of_accommodation', 'room_type_reserved_Room_Type 4', 'no_of_adults']
### Итоговые признаки
Итоговое количество отобранных признаков: 13
Итоговые отобранные признаки: {'avg_price_per_room', 'no_of_week_nights', 'arrival_date', 'booking_type', 'type_of_accommodation', 'season', 'lead_time', 'no_of_adults', 'no_of_weekend_nights', 'no_of_special_requests', 'market_segment_type', 'type_of_meal_plan', 'arrival_month'}
## Baseline - логистическая регрессия
В коде используются библиотеки для анализа данных и построения моделей машинного обучения. matplotlib и seaborn отвечают за визуализацию данных с помощью графиков. pandas используется для удобной работы с табличными данными, а numpy - для численных вычислений. sklearn предоставляет инструменты для предварительной обработки данных, разделения на обучающую и тестовую выборки, выбора оптимальных параметров модели, обучения моделей (например, логистической регрессии) и оценки их качества. Для работы с несбалансированными данными применяется библиотека imblearn, в частности метод SMOTE.

Программа считывает данные из файла “Final_features.csv” в DataFrame, после чего анализирует распределение значений в столбце “booking_status” для оценки баланса классов в наборе данных.
````
booking_status
1    22053
0    10559
Name: count, dtype: int64
````
Данные разделяются на признаки (X) и целевую переменную (y), а затем разделяются на обучающую и тестовую выборки, при этом 30% данных выделяется для тестирования, случайность фиксируется для воспроизводимости, и обеспечивается сохранение пропорций классов целевой переменной в обеих выборках.

На данном этапе выполняется масштабирование признаков в обучающей и тестовой выборках с использованием StandardScaler, чтобы привести их к единому масштабу и улучшить производительность моделей машинного обучения.
````
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)
````
На данном этапе решается проблема дисбаланса классов в обучающей выборке: сначала выводится текущее распределение классов, затем применяется метод SMOTE для создания синтетических образцов миноритарного класса, и после этого снова выводится распределение классов, чтобы показать эффект от применения SMOTE.
````
Баланс классов в y_train до обработки: booking_status
1    15437
0     7391
Name: count, dtype: int64
Баланс классов в y_train после обработки: booking_status
0    15437
1    15437
Name: count, dtype: int64
````
С помощью GridSearchCV подбираются оптимальные параметры для модели логистической регрессии, используя кросс-валидацию для оценки качества и метрику recall для оптимизации, а затем сохраняется лучшая обученная модель. Лучшие параметры: {'solver': 'lbfgs'}.

В этом блоке оценивается производительность лучшей модели логистической регрессии на тестовых данных: вычисляется accuracy, строится и отображается матрица ошибок, и выводится отчет о классификации, содержащий precision, recall, F1-score и другие метрики.
````
Accuracy: 0.767988552739166
Confusion Matrix:
 [[2444  724]
 [1546 5070]]
Classification Report:
               precision    recall  f1-score   support

           0       0.61      0.77      0.68      3168
           1       0.88      0.77      0.82      6616

    accuracy                           0.77      9784
   macro avg       0.74      0.77      0.75      9784
weighted avg       0.79      0.77      0.77      9784
````
Модель логистической регрессии показала общую точность 76.80% в предсказании классов. Анализ отчета о классификации выявил, что модель с большей уверенностью предсказывает класс 1 (состоявшиеся бронирования), с точностью 88%, но при этом не все случаи класса 1 были верно идентифицированы (recall 77%). Класс 0 (отмененные бронирования) предсказывается с меньшей точностью (61%), что означает, что модель часто ошибочно относит состоявшиеся бронирования к отмененным. Матрица ошибок подтверждает это, показывая, что большое количество случаев класса 1 (1546) было ошибочно классифицировано как класс 0.

На данном этапе настраивается порог вероятности для классификации и оценивается влияние этого порога на производительность модели: сначала извлекаются вероятности принадлежности к классу 1, затем устанавливается новый порог (0.6), формируются предсказания на основе этого порога, и, наконец, оценивается модель с использованием новых предсказаний, выводятся метрики accuracy, confusion matrix и classification report.
````
Оценка модели с новым порогом (0.6):
Accuracy: 0.7333401471790678
Confusion Matrix:
 [[2688  480]
 [2129 4487]]
Classification Report:
               precision    recall  f1-score   support

           0       0.56      0.85      0.67      3168
           1       0.90      0.68      0.77      6616

    accuracy                           0.73      9784
   macro avg       0.73      0.76      0.72      9784
weighted avg       0.79      0.73      0.74      9784
````
Изменив порог классификации логистической регрессии на 0.6, общая точность снизилась до 73.33%. Хотя recall для класса 0 (отмененные бронирования) вырос, что было приоритетом, precision для этого класса упал, увеличив число ложных срабатываний. Recall для класса 1 (состоявшиеся бронирования) при этом снизился. Матрица ошибок подтверждает, что состоявшиеся бронирования стали чаще классифицироваться как отмененные.

Затем строится ROC-кривая и вычисляется AUC-ROC для оценки качества модели с использованием настроенного порога вероятности, отображая графически соотношение между True Positive Rate и False Positive Rate и численно оценивая общую производительность модели.

Вычисляются вероятности принадлежности каждого объекта тестовой выборки к классу 1 (y_proba) и классу 0 (y_proba_class0), используя обученную модель логистической регрессии.
````
y_proba = best_log_model.predict_proba(scaled_X_test)[:, 1]  # Вероятности для класса 1
y_proba_class0 = 1-y_proba # Вероятности для класса 0
````
Строится ROC-кривая и вычисляется площадь под ней (AUC) для оценки производительности модели, визуализируя соотношение между True Positive Rate и False Positive Rate и предоставляя численную оценку качества классификации.

На данном этапе вычисляются вероятности принадлежности каждого объекта тестовой выборки к каждому из классов (0 и 1), используя обученную модель логистической регрессии. Результат сохраняется в переменной proba.
````
proba = best_log_model.predict_proba(scaled_X_test)
````
Создается DataFrame, содержащий вероятности принадлежности к каждому классу, фактические значения целевой переменной и предсказанные значения, полученные с использованием выбранного порога.
````
proba_df = pd.DataFrame(proba, columns=['Probability_Class_0', 'Probability_Class_1'])
proba_df['Actual_Class'] = y_test.values
proba_df['Predicted_Class'] = y_pred_threshold
````
Выводятся первые несколько строк DataFrame, содержащего вероятности принадлежности к классам, фактические значения и предсказанные классы для тестовых данных, что позволяет визуально оценить качество предсказаний модели.
````
Вероятности принадлежности к классам для тестовых данных:
   Probability_Class_0  Probability_Class_1  Actual_Class  Predicted_Class
0                 0.31                 0.69             1                1
1                 0.31                 0.69             1                1
2                 0.48                 0.52             1                0
3                 0.12                 0.88             1                1
4                 0.07                 0.93             1                1
````
Извлекается и выводится вероятность бронирования (принадлежности к классу 1) для конкретного экземпляра (в данном случае, первого) из DataFrame, содержащего вероятности предсказаний. Вероятность бронирования для экземпляра 0: 0.6870

## Модель DecisionTree
Импортируются библиотеки pandas для работы с табличными данными, train_test_split, GridSearchCV и StratifiedKFold из sklearn.model_selection для разделения данных, подбора параметров и организации кросс-валидации, DecisionTreeClassifier из sklearn.tree для построения модели дерева решений, accuracy_score, classification_report, confusion_matrix, recall_score и make_scorer из sklearn.metrics для оценки качества модели, SMOTE из imblearn.over_sampling для обработки дисбаланса классов, StandardScaler из sklearn.preprocessing для масштабирования признаков, а также matplotlib.pyplot и seaborn для визуализации данных.

Загружаются данные из CSV-файла “Final_features.csv” в DataFrame pandas, а затем выделяются признаки (X) путем удаления столбца “booking_status” и целевая переменная (y) из столбца “booking_status”.

Исходные данные разделяются на обучающую и тестовую выборки в соотношении 70/30, при этом используется стратификация (stratify=y) для сохранения пропорций классов в обеих выборках, и фиксируется random_state=77 для воспроизводимости результатов.

Выполняется стандартизация признаков путем масштабирования обучающей выборки с использованием StandardScaler (вычисляются среднее и стандартное отклонение), а затем применяется то же преобразование к тестовой выборке, чтобы избежать утечки данных.

Применяется техника SMOTE (Synthetic Minority Oversampling Technique) к обучающей выборке для устранения дисбаланса классов путем генерации синтетических образцов миноритарного класса, увеличивая его представленность.

Задается сетка параметров (param_grid) для поиска оптимальной конфигурации дерева решений, включающая различные значения для критерия разделения (criterion), максимальной глубины дерева (max_depth), минимального количества выборок для разделения узла (min_samples_split) и минимального количества выборок в листе (min_samples_leaf).

Создается экземпляр модели дерева решений (DecisionTreeClassifier) с фиксированным random_state=77 для обеспечения воспроизводимости результатов.

Настраивается GridSearchCV для поиска оптимальных параметров модели дерева решений, используя стратифицированную кросс-валидацию с 5 фолдами (StratifiedKFold), метрику recall для оценки качества, подробный вывод процесса обучения (verbose=2) и все доступные ядра процессора (n_jobs=-1).
````
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=77)
recall_scorer = make_scorer(recall_score)
grid_search = GridSearchCV(estimator=dt_model,
                           param_grid=param_grid,
                           cv=cv,
                           scoring=recall_scorer,
                           verbose=2,
                           n_jobs=-1)
````
Производится обучение модели дерева решений с использованием GridSearchCV на передискретизированной обучающей выборке (over_X_train, over_y_train) для поиска наилучшей комбинации параметров, заданных в param_grid.

Выводятся наилучшие параметры модели дерева решений, найденные в процессе обучения с использованием GridSearchCV. Лучшие параметры: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}.

Из объекта grid_search извлекается лучшая модель дерева решений, обученная с использованием оптимальных параметров, найденных в процессе кросс-валидации.

Используя лучшую обученную модель дерева решений, выполняются предсказания целевой переменной на тестовой выборке.

Оценивается качество предсказаний модели на тестовой выборке, выводятся метрика точности (accuracy) и отчет о классификации, содержащий precision, recall, F1-score для каждого класса.
````
Точность (Accuracy): 0.8679476696647588
Отчет о классификации:
               precision    recall  f1-score   support

           0       0.79      0.81      0.80      3168
           1       0.91      0.90      0.90      6616

    accuracy                           0.87      9784
   macro avg       0.85      0.85      0.85      9784
weighted avg       0.87      0.87      0.87      9784
````
Вычисляется и выводится матрица ошибок, которая показывает количество правильно и неправильно классифицированных объектов для каждого класса.
````
Матрица ошибок:
 [[2557  611]
 [ 681 5935]]
````
Визуализируется матрица ошибок с использованием тепловой карты (heatmap) для более наглядного представления результатов классификации, где по осям отложены фактические и предсказанные классы.

Модель дерева решений, обученная с использованием GridSearchCV и оптимизированная по метрике recall, показала общую точность 86.74%. Лучшие параметры: entropy criterion, максимальная глубина 20, минимум 1 образец в листе и минимум 2 для разделения. Модель хорошо предсказывает состоявшиеся бронирования (класс 1), но несколько хуже определяет отмененные (класс 0), что видно из матрицы ошибок, где количество ложноположительных срабатываний для класса 0 значительно. Дальнейшие улучшения следует направить на повышение точности предсказания отмен, возможно, через расширение набора признаков или изменение подхода к балансировке классов.

## Модель - GradientBoostingClassifier
Код импортирует библиотеки для машинного обучения, включая инструменты для работы с данными, разделения на выборки, алгоритм градиентного бустинга, оценку качества модели, обработку дисбаланса классов и визуализацию.

Загружаются данные из CSV-файла “Final_features.csv” в DataFrame pandas, а затем выделяются признаки (X) путем удаления столбца “booking_status” и целевая переменная (y) из столбца “booking_status”.

Исходные данные разделяются на обучающую и тестовую выборки в соотношении 70/30, при этом используется стратификация (stratify=y) для сохранения пропорций классов в обеих выборках, и фиксируется random_state=77 для воспроизводимости результатов.

Выполняется стандартизация признаков путем масштабирования обучающей выборки с использованием StandardScaler (вычисляются среднее и стандартное отклонение), а затем применяется то же преобразование к тестовой выборке, чтобы избежать утечки данных.

Применяется техника SMOTE (Synthetic Minority Oversampling Technique) к обучающей выборке для устранения дисбаланса классов путем генерации синтетических образцов миноритарного класса, увеличивая его представленность.

Определяем сетку гиперпараметров (param_grid), которые будут перебираться для настройки модели. Указываются различные значения для количества деревьев в ансамбле (n_estimators), скорости обучения (learning_rate), максимальной глубины каждого дерева (max_depth), минимального количества образцов для разделения внутреннего узла (min_samples_split) и минимального количества образцов в листовом узле (min_samples_leaf). GridSearchCV будет использовать эти значения для поиска оптимальной комбинации гиперпараметров.
````
param_grid = {
    'n_estimators': [50, 100, 200, 300],  # Количество деревьев
    'learning_rate': [0.01, 0.05, 0.1, 0.2], # Скорость обучения
    'max_depth': [3, 5, 7],                # Максимальная глубина дерева
    'min_samples_split': [2, 5, 10],       # Мин. количество выборок для разделения узла
    'min_samples_leaf': [1, 2, 4],         # Мин. количество выборок в листовом узле
}
````
Создаем экземпляр модели градиентного бустинга (GradientBoostingClassifier) с фиксированным случайным состоянием (random_state=77) для обеспечения воспроизводимости результатов.

Настраиваем GridSearchCV для поиска оптимальных гиперпараметров модели градиентного бустинга. Перебираем все комбинации параметров, заданных в param_grid, используя 3-кратную кросс-валидацию для оценки каждой комбинации. Оценка производится на основе метрики recall. Параметр verbose=2 включает подробный вывод процесса поиска, а n_jobs=-1 указывает использовать все доступные ядра процессора для ускорения вычислений.

Запускаем процесс обучения модели с использованием GridSearchCV. Берем модель gb_model и сетку гиперпараметров param_grid, и для каждой комбинации гиперпараметров обучает и оценивает модель на тренировочных данных (over_X_train, over_y_train), сгенерированных методом SMOTE (передискретизация для борьбы с дисбалансом классов). GridSearchCV автоматически находит наилучшую комбинацию гиперпараметров, максимизирующую метрику recall на кросс-валидации.

Выводим на экран наилучшие значения гиперпараметров, найденные GridSearchCV в процессе обучения. Эти параметры, по результатам кросс-валидации, обеспечили наилучшую производительность модели, измеренную метрикой recall.

Извлекаем лучшую обученную модель из объекта GridSearchCV. best_estimator_ содержит модель GradientBoostingClassifier, обученную с использованием оптимальных гиперпараметров, найденных в процессе перебора. Теперь best_gb_model можно использовать для предсказаний на новых данных.

Используем лучшую обученную модель (best_gb_model), чтобы сделать предсказания (y_pred) на тестовой выборке данных (X_test). Результатом является вектор y_pred, содержащий предсказанные значения целевой переменной для каждой записи в тестовом наборе.

Выводим на экран метрики, оценивающие качество предсказаний модели на тестовой выборке.

Точность (Accuracy): Общая доля правильно классифицированных примеров. Отчет о классификации (Classification Report): Более подробный отчет, включающий precision, recall, F1-score и support для каждого класса. Эти метрики показывают, насколько хорошо модель предсказывает каждый класс.

Создаем и выводим на экран матрицу ошибок (confusion_matrix), которая показывает количество правильно и неправильно классифицированных экземпляров для каждого класса. Строки матрицы соответствуют фактическим классам, а столбцы – предсказанным классам. Анализ матрицы ошибок позволяет оценить, какие классы модель путает чаще всего и какие типы ошибок преобладают (ложноположительные или ложноотрицательные).

Визуализируется матрица ошибок с использованием тепловой карты (heatmap) для более наглядного представления результатов классификации, где по осям отложены фактические и предсказанные классы.

Модель демонстрирует хорошую общую производительность, особенно хорошо распознавая объекты класса 1. Однако, есть возможности для улучшения способности модели распознавать объекты класса 0.

## Модель - Random Forest
Код импортирует библиотеки для машинного обучения, включая инструменты для работы с данными, разделения на выборки, алгоритм градиентного бустинга, оценку качества модели, обработку дисбаланса классов и визуализацию.

Загружаются данные из CSV-файла “Final_features.csv” в DataFrame pandas, а затем выделяются признаки (X) путем удаления столбца “booking_status” и целевая переменная (y) из столбца “booking_status”.

Исходные данные разделяются на обучающую и тестовую выборки в соотношении 70/30, при этом используется стратификация (stratify=y) для сохранения пропорций классов в обеих выборках, и фиксируется random_state=77 для воспроизводимости результатов.

Выполняется стандартизация признаков путем масштабирования обучающей выборки с использованием StandardScaler (вычисляются среднее и стандартное отклонение), а затем применяется то же преобразование к тестовой выборке, чтобы избежать утечки данных.

Применяется техника SMOTE (Synthetic Minority Oversampling Technique) к обучающей выборке для устранения дисбаланса классов путем генерации синтетических образцов миноритарного класса, увеличивая его представленность.

Определяется набор параметров, которые будут меняться в процессе поиска наилучшей модели. Это количество деревьев в ансамбле, максимальная глубина каждого дерева, минимальное количество объектов для разделения узла, минимальное количество объектов в конечном листе и способ учета дисбаланса классов.

Создаем объект модели “Случайный лес” (RandomForestClassifier) с фиксированным значением random_state=77. Это необходимо для того, чтобы при повторном запуске кода с теми же данными и параметрами, результаты обучения модели были идентичными (воспроизводимость). RandomForestClassifier - это ансамблевый метод машинного обучения, который использует множество деревьев решений для повышения точности и предотвращения переобучения.

Происходит настройка инструмента автоматического подбора гиперпараметров, который называется GridSearchCV. Он будет искать наилучшие значения параметров для модели случайного леса, перебирая разные варианты, определенные в param_grid. Оценка каждого варианта будет происходить с использованием трехкратной кросс-валидации и метрики recall. Для ускорения процесса используются все доступные вычислительные ядра, а на экран выводится подробная информация о ходе подбора.

Запускается обучение модели случайного леса и одновременный подбор лучших значений её параметров на тренировочных данных, возможно сбалансированных, используя кросс-валидацию для оценки качества.

Выводим на экран оптимальные значения гиперпараметров, которые были найдены алгоритмом GridSearchCV в процессе обучения модели. grid_search.best_params_ содержит словарь, где ключи - названия гиперпараметров, а значения - лучшие найденные для них значения. Эти параметры дали наилучшие результаты на кросс-валидации, используя выбранную метрику оценки (в данном случае, recall). Этот вывод позволяет увидеть, какая комбинация параметров оказалась наиболее эффективной для данной задачи и наборе данных.

Из объекта GridSearchCV извлекается лучшая обученная модель, которая была настроена на оптимальных гиперпараметрах.

Используем лучшую, уже обученную и настроенную модель случайного леса (best_rf_model) для того, чтобы сделать предсказания y_pred для данных, которые модель еще не видела - тестовой выборки X_test. Эти предсказания затем используются для оценки качества модели на новых данных.

Выводится оценка качества предсказаний модели, полученных на тестовой выборке. Выводится общая доля правильных ответов (accuracy) и более подробный отчет, включающий precision, recall, F1-score и support для каждого класса.

Создается и выводится матрица ошибок, показывающая количество правильно и неправильно классифицированных объектов для каждого класса. Строки матрицы соответствуют фактическим классам, а столбцы – предсказанным.

Визуализируется матрица ошибок с использованием тепловой карты (heatmap) для более наглядного представления результатов классификации, где по осям отложены фактические и предсказанные классы.

Итоговая модель, обученная с автоматической настройкой параметров, показывает хорошие результаты. Точность составляет около 90%, что говорит о высокой доле правильных предсказаний. Модель хорошо выявляет объекты класса “1” (recall 93%), но чуть хуже справляется с классом “0” (recall 83%). Матрица ошибок подтверждает, что модель чаще ошибочно относит объекты класса “0” к классу “1”. Это может быть связано с дисбалансом классов в данных.


